Dataset:
  train: Dataset/train
  valid: Dataset/valid
  test: Dataset/test

  # Test
  use_onnx_model: False
  save_flag: True
  save_path: result
  show_flag: False
  decode_number: -1 # decode할 개수
  nms_thresh: 0.5
  nms_topk: 1000 # 전체 다하면(-1) 너무 오래걸림.
  except_class_thresh: 0.01 #0.05
  plot_class_thresh: 0.5 # 그릴때 score_thresh 보다 큰 것들만 그린다.
  test_graph_path: test_Graph

model:
  training: True
  load_name: 256_512_ADAM_PRES_18 # training = False,
  save_period: 200
  load_period: 200
  input_size: [256, 512] # height, width
  ResNetbase: 18 # resnet base version : 18, 34, 50, 101, 152
  pretrained_base: True
  pretrained_path: modelparam
  graphviz: False

hyperparameters:

  # model 관련
  image_mean: [0.485, 0.456, 0.406] # R G B
  image_std:  [0.229, 0.224, 0.225] # R G B
  anchor_sizes: [32, 64, 128, 256, 512]
  anchor_size_ratios: "[1, pow(2, 1 / 3), pow(2, 2 / 3)]"
  anchor_aspect_ratios: [0.5, 1, 2]
  anchor_box_clip: True

  # 학습 관련
  epoch: 200
  batch_size: 16
  multiscale: True
  factor_scale: [8, 5] # input_size(height, width)를 8으로 나눈 값에, 6,7,8,9,10 5개를 곱한 값을 width height로 사용
  data_augmentation: True
  num_workers: 4 # the number of multiprocessing workers to use for data preprocessing.
  optimizer: ADAM # ADAM, RMSP, SGD
  learning_rate: 0.0001
  decay_lr: 0.999
  decay_step: 100 # 몇 epoch이 지난후 decay_lr을 적용할지
  AMP: True # https://mxnet.apache.org/api/python/docs/tutorials/performance/backend/amp.html# / available on new Volta and Turing GPUs
context:
  using_cuda: True
validation:
  eval_period: 200
  tensorboard: True
  valid_graph_path: valid_Graph
mlflow:
  using_mlflow: True
  run_name: Animal




